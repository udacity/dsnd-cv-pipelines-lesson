{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Optimizing Full Computer Vision Pipeline\n",
    "\n",
    "In this exercise, we'll classify fashion items with support vector machines in scikit-learn. We will now wrap OpenCV in a custom scikit-learn transformer to combine OpenCV's computer vision methods with scikit-learns powerful pipeline functionalities. \n",
    "\n",
    "Your tasks are the following:\n",
    "\n",
    "- Optimize the whole computer vision pipeline using grid search and cross validation\n",
    "- Evaluate the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Acquisition and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the MNIST dataset\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and test data\n",
    "X_train, y_train = load_mnist('../../images/fashion', kind='train')\n",
    "X_test, y_test = load_mnist('../../images/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "idx = np.arange(len(X_train))\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# we'll only use 10% of the data for speed-up\n",
    "X_train = X_train[:int(.10*len(idx))]\n",
    "y_train = y_train[:int(.10*len(idx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the labels\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first 10 images\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    ax[i//5, i%5].imshow(X_train[i].reshape(28, 28), cmap='gray')\n",
    "    ax[i//5, i%5].axis('off')\n",
    "    ax[i//5, i%5].set_title(classes[y_train[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a Support Vector Machine for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a support vector machine to the data\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='linear', random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some images and their predicted and true labels\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_test[i].reshape(28, 28), cmap='binary')\n",
    "    ax.set_title('True: %s\\nPredicted: %s' % (classes[y_test[i]], classes[y_pred[i]]))\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using OpenCV within Scikit-Learn-Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a custom transformer that extracts HOG features from the images\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class OpenCVFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_type='hog'):\n",
    "        self.feature_type = feature_type\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing to fit\n",
    "\n",
    "    def transform(self, X):\n",
    "        # X shape is (n_samples, 784) for Fashion MNIST\n",
    "        # We need to reshape to (n_samples, 28, 28) first\n",
    "        X_images = X.reshape(-1, 28, 28)\n",
    "        features = []\n",
    "        \n",
    "        for image in X_images:\n",
    "            # Convert to uint8 for OpenCV\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "            \n",
    "            if self.feature_type == 'hog':\n",
    "                # Calculate HOG features\n",
    "                winSize = (28, 28)\n",
    "                blockSize = (14, 14)\n",
    "                blockStride = (7, 7)\n",
    "                cellSize = (7, 7)\n",
    "                nbins = 9\n",
    "                hog = cv2.HOGDescriptor(winSize, blockSize, \n",
    "                                      blockStride, cellSize, nbins)\n",
    "                feature = hog.compute(image)\n",
    "                \n",
    "            elif self.feature_type == 'edges':\n",
    "                # Calculate edge features using Canny\n",
    "                edges = cv2.Canny(image, 50, 150)\n",
    "                feature = edges.flatten()\n",
    "            \n",
    "            features.append(feature.flatten())\n",
    "            \n",
    "        return np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with the custom transformer and SVM\n",
    "pipeline = Pipeline([\n",
    "    ('features', OpenCVFeatureExtractor(feature_type='hog')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='linear', random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_custom_pipeline = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %.2f' % accuracy_custom_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimizing the Full Computer Vision Pipeline\n",
    "\n",
    "**TODO**: Fine-tune your model using grid search over the whole pipeline. Optimize over the SVM parameters from the last exercise as well as the extracted OpenCV features - all in one shot!\n",
    "\n",
    "**WARNING**: Grid search becomes computationally expensive quite fast, so start with optimizing only a few parameters to avoid long runtimes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: YOUR CODE GOES HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Retrieve the best model from the grid search and calculate the final accuracy on the test data! Which features should OpenCV extract?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: YOUR CODE GOES HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
